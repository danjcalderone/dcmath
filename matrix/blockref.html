<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"></link>
    <meta http-equiv="X-UA-Compatible" content="ie=edge" ></link>

    <link
    rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.css"
    integrity="sha384-Cqd8ihRLum0CCg8rz0hYKPoLZ3uw+gES2rXQXycqnL5pgVQIflxAUDS7ZSjITLb5"
    crossorigin="anonymous"></link>

  <!-- The loading of KaTeX is deferred to speed up page rendering -->
  <script
    defer
    src="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.js"
    integrity="sha384-1Or6BdeNQb0ezrmtGeqQHFpppNd7a/gw29xeiSikBbsb44xu3uAo8c7FwbF5jhbd"
    crossorigin="anonymous"></script>
  <!-- To automatically render math in text elements, include the auto-render extension: -->

  <script
    defer
    src="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/contrib/auto-render.min.js"
    integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl"
    crossorigin="anonymous"
    onload="renderMathInElement(document.body)">
    </script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjs/6.2.5/math.min.js"> </script>
  <script src="https://unpkg.com/pts@0.10.5/dist/pts.js"></script>






      <link rel="stylesheet" href="/dcmath/css/main.css" ></link>
      </head>

      <body>
      <header> <h1> .dcmath - UNDER CONSTRUCTION </h1> </header>
      <div w3-include-html="/dcmath/nav/topics.html"></div>
      <!-- <div w3-include-html="nav/topics.html"></div> -->
      <div class="wrapper">
        <div class="sidebar">
        <div w3-include-html="/dcmath/nav/sidebarMATRIX.html"></div>
        </div>
        <div class=content>


          <div class=header style="font-size:40"> Block Matrix Structures </div>



<!--
          <div class=module>
            <div style:'flex:1'>
            <div class=header style="font-size:40"> Inverse Reference </div>


            <div class='img' style="padding:0px" id="matrices-container">
                <canvas class='CANVAS' id='matrices'  ></canvas>
                <div class="eqn" id="eqn1y" ></div>
                <div class="eqn" id="eqn1A" ></div>
                <div class="eqn" id="eqn1B" ></div>
                <div class="eqn" id="eqn1C" ></div>
                <div class="eqn" id="eqn1D" ></div>
                <div class="eqn" id="eqn1x" ></div>

                <div class="eqn" id="y_vec" ></div>
                <div class="eqn" id="A_vec" ></div>
                <div class="eqn" id="x_vec" ></div>
                <div class="eqn" id="Amaps_vec" ></div>
                <div class="eqn" id="label2_vec" ></div>
                <div class="eqn" id="warning2_vec" ></div>
                <div class="eqn" id="usedigits_vec" ></div>
              </div>

            </div>

            <div class="text" >

              <b> ROTATION MATRIX </b>
              <p>

              The inverse of a rotation matrix is its transpose

              $$  R^{-1} = R^T $$
              This relationship is equivalent to the columns being orthonormal.
              Explicitly
              $$ R^{-1}R = R^TR =I $$

              $$ R^TR =
              \begin{bmatrix}
              - & R_1^T & - \\
              & \vdots & \\
              - & R_n^T & - \\
              \end{bmatrix}
              \begin{bmatrix}
              | & & | \\
              R_1 & \cdots & R_n \\
              | & & |
              \end{bmatrix}
              $$
              $$
              \begin{bmatrix}
              R_1^TR_1 & \cdots & R_1^TR_n \\
              \vdots & \ddots  & \vdots \\
              R_n^TR_1 & \cdots & R_n^TR_n
              \end{bmatrix}
              =
              \begin{bmatrix}
              1 & \cdots & 0 \\
              \vdots & \ddots & \vdots \\
              0 & \cdots  & 1
              \end{bmatrix}
              $$
              Elementwise:

              $$ R_i^TR_j =
              \begin{cases}
              1 & i = j
              0 & i \neq j
              \end{cases}
              $$

              Visually this means the columns (and rows) of \(R\) are orthogonal vectors on the unit sphere.

              </p>

              <p>
              Example: a counter-clockwise 2D rotation given by
              $$
              R_{2 \times 2} =
              \begin{bmatrix}
              \cos \theta & - \sin \theta \\
              \sin \theta & \cos \theta
              \end{bmatrix}
              $$
              </p>

                </div>
              </div> -->

              <div class='imgFixed'>
              <img src="/dcmath/figs/stills/BLOCK/mmregular.png" width=100%></img>
              </div>



              <div class="txt" style="padding:40px, width:100%">
              <b> General Block Matrix Multiplication </b>
              <p>
              $$
              A =
              \begin{bmatrix}
              A_{11} & \cdots & A_{1J} \\
              \vdots & & \vdots \\
              A_{I1} & \cdots & A_{IJ}
              \end{bmatrix},\qquad
              B =
              \begin{bmatrix}
              B_{11} & \cdots & B_{1K} \\
              \vdots & & \vdots \\
              B_{J1} & \cdots & B_{JK}
              \end{bmatrix}
              $$

              $$
              AB =
              \begin{bmatrix}
              A_{11}B_{11}+\cdots+ A_{1J}B_{J1} & \cdots & A_{11}B_{1K}+\cdots+ A_{1J}B_{JK} \\
              \vdots & & \vdots \\
              A_{I1}B_{11}+\cdots+ A_{IJ}B_{J1} & \cdots & A_{I1}B_{1K}+\cdots+ A_{IJ}B_{JK}
              \end{bmatrix}
              $$

              $$
              AB =
              \begin{bmatrix}
              \sum_j A_{1j}B_{j1} & \cdots & \sum_j A_{1j}B_{jK} \\
              \vdots & & \vdots \\
              \sum_j A_{Ij}B_{j1} & \cdots & \sum_jA_{Ij}B_{jK}
              \end{bmatrix}
              $$
              The inner blocks can be any dimensions as long as dimensions that need to match up are the same.
              For example \(A_{ij}\) and \(B_{jk}\) need to have matching inner dimensions (the \(j\) dimension)
              so that the multiplication \(A_{ij}B_{jk}\) makes sense.


              </p>
              </div>




              <div class='imgFixed'>
              <img src="/dcmath/figs/stills/BLOCK/mmblock.png" width=100%></img>
              </div>










              <div class='imgFixed'>
              <img src="/dcmath/figs/stills/BLOCK/mvcols.png" width=100%></img>
              </div>


              <div class="txt" style="padding:40px, width:100%">
              <b> Case 1: Linear Combination of Columns - MOST IMPORTANT </b>


              <p>
                For matrix \(A \in \mathbb{R}^{m \times n}\) and vector \(x \in \mathbb{R}^n \)
                the product \(Ax\) can be thought of as a linear combination
                of the columns of \(A\) with coefficients given by the coordinates of \(x\).
                $$
                Ax =
                \begin{bmatrix}
                | & & |\\
                A_1 & \cdots & A_n \\
                | & & |\\
                \end{bmatrix}
                \begin{bmatrix}
                x_1 \\ \vdots \\ x_n
                \end{bmatrix}
                =
                \begin{bmatrix}
                | \\
                A_1 \\
                |
                \end{bmatrix}
                x_1
                + \cdots +
                \begin{bmatrix}
                | \\
                A_n \\
                |
                \end{bmatrix}
                x_n
                $$
                Being comfortable with this interpretation is critical to fluency in linear algebra.
              </p>

            </div>


              <div class='imgFixed'>
              <img src="/dcmath/figs/stills/BLOCK/mvrows.png" width=100%></img>
              </div>


              <div class="txt" style="padding:40px, width:100%">

              <b> Case 2: Projection Onto Rows </b>


              <p>
                For matrix \(A \in \mathbb{R}^{M \times N}\) and vector \(x \in \mathbb{R}^N \)
                if we think of the matrix as rows, the product \(Ax\) is the inner product of
                \(x\) with each of the rows.


                $$
                Ax =
                \begin{bmatrix}
                - & a_1^T & - \\
                \vdots & & \vdots \\
                - & a_N^T & -
                \end{bmatrix}
                \begin{bmatrix}
                | \\
                x \\
                |
                \end{bmatrix}
                =
                \begin{bmatrix}
                 a_1^Tx \\
                \vdots \\
                a_N^Tx
                \end{bmatrix}
                $$
              </p>

            </div>


            <div class='imgFixed'>
            <img src="/dcmath/figs/stills/BLOCK/vmcols.png" width=100%></img>
            </div>

            <div class='imgFixed'>
            <img src="/dcmath/figs/stills/BLOCK/vmrows.png" width=100%></img>
            </div>

                        <div class='imgFixed'>
                        <img src="/dcmath/figs/stills/BLOCK/mmcols.png" width=100%></img>
                        </div>

              <div class="txt" style="padding:40px, width:100%">

              <b> Case 3: Each Column a Set of Coordinates  </b>


              <p>
                Multiplying a matrix \(A\) with a matrix \(B\) can be thought of as applying
                the tranformation \(A\) to each column of the matrix \(B\) separately.
                For matrix \(A \in \mathbb{R}^{M \times N}\) and matrix \(B \in \mathbb{R}^{N \times K}\)
                $$
                AB = \bigg[ \ \  A \  \ \bigg]
                \begin{bmatrix}
                | & & |\\
                B_1 & \cdots & B_n \\
                | & & |\\
                \end{bmatrix}
                =
                \begin{bmatrix}
                | & & |\\
                AB_1 & \cdots & AB_n \\
                | & & |\\
                \end{bmatrix}
                $$
                Combining this with the first case, we have that each column, \(B_j\)
                corresponds to a different linear combination of the columns of \(A\).
              </p>

            </div>







              <div class='imgFixed'>
              <img src="/dcmath/figs/stills/BLOCK/mmrows.png" width=100%></img>
              </div>



              <div class='imgFixed'>
              <img src="/dcmath/figs/stills/BLOCK/mmrowscols.png" width=100%></img>
              </div>





              <div class="txt" style="padding:40px, width:100%">


              <b> Case 4: Pairwise Inner Products </b>



              <p>
                If \(A\) is segmented into rows and \(B\) is segmented into columns,
                \(AB\) is the pairwise inner products between rows of \(A\) and
                columns of \(B\).


                $$
                AB =
                \begin{bmatrix}
                - & a_1^T & - \\
                \vdots & & \vdots \\
                - & a_N^T & -
                \end{bmatrix}
                \begin{bmatrix}
                | & & |\\
                B_1 & \cdots & B_n \\
                | & & |\\
                \end{bmatrix}
                =
                \begin{bmatrix}
                \underbrace{a_1^TB_1}_{1 \times 1} & \cdots & a_1^TB_K \\
                \vdots & & \vdots  \\
                a_M^TB_1 & \cdots & a_M^TB_K
                \end{bmatrix}
                $$
              </p>

            </div>

            <div class='imgFixed'>
            <img src="/dcmath/figs/stills/BLOCK/mmcolsrows.png" width=100%></img>
            </div>







          <div class="txt" style="padding:40px, width:100%">



              <b> Case 5: Sum of Outer Products </b>
              <p>
                If \(A\) is segmented into cols and \(B\) is segmented into rows,
                \(AB\) is a sum of outer-products.


                $$
                AB =
                \begin{bmatrix}
                | & & |\\
                A_1 & \cdots & A_N \\
                | & & |\\
                \end{bmatrix}
                \begin{bmatrix}
                - & b_1^T & - \\
                \vdots & & \vdots \\
                - & b_N^T & -
                \end{bmatrix}
                =
                \underbrace{
                \begin{bmatrix}
                | \\
                A_1 \\
                |
                \end{bmatrix}
                \begin{bmatrix}
                - & b_1^T & -
                \end{bmatrix}
              }_{M \times K}
                + \cdots +
                \begin{bmatrix}
                | \\
                A_N \\
                |
                \end{bmatrix}
                \begin{bmatrix}
                - & b_N^T & -
                \end{bmatrix}
                = \sum_j A_jb_j^T
                $$
              </p>


            </div>



            <div class='imgFixed'>
            <img src="/dcmath/figs/stills/BLOCK/mmmrowsmatcols.png" width=100%></img>
            </div>


            <div class="txt" style="padding:40px, width:100%">
            <b> Case 6: Inner Products Around Matrix </b>
            <p>
              If \(A\) is segmented into rows, \(B\) is segmented into cols,
              and \(D\) is some matrix of appropriate dimension, the product
              \(ADB\) is given by


              $$
              ADB =
              \begin{bmatrix}
              - & a_1^T & - \\
              \vdots & & \vdots \\
              - & a_N^T & -
              \end{bmatrix}
              \Bigg[ \ \ \ D \ \ \ \Bigg]
              \begin{bmatrix}
              | & & |\\
              B_1 & \cdots & B_n \\
              | & & |\\
              \end{bmatrix}
              =
              \begin{bmatrix}
              \underbrace{a_1^TDB_1}_{1 \times 1} & \cdots & a_1^TDB_K \\
              \vdots & & \vdots  \\
              a_M^TDB_1 & \cdots & a_M^TDB_K
              \end{bmatrix}
              $$
            </p>
          </div>


          <div class='imgFixed'>
          <img src="/dcmath/figs/stills/BLOCK/mmmcolsvalsrows.png" width=100%></img>
          </div>



            <div class="txt" style="padding:40px, width:100%">

              <b> Case 7: Outer Products Around Matrix </b>
              <p>
                If \(A\) is segmented into cols, \(B\) is segmented into rows,
                and \(D\) is some matrix of appropriate dimension, the product
                \(ADB\) is given by
                $$
                AB =
                \begin{bmatrix}
                | & & |\\
                A_1 & \cdots & A_N \\
                | & & |\\
                \end{bmatrix}
                \underbrace{
                \begin{bmatrix}
                d_{11} & \cdots & d_{1K} \\
                \vdots & & \vdots \\
                d_{N1} & \cdots & d_{NK}
                \end{bmatrix}
              }_{D}
                \begin{bmatrix}
                - & b_1^T & - \\
                \vdots & & \vdots \\
                - & b_K^T & -
                \end{bmatrix}
                =
                \sum_j \sum_k
                \underbrace{
                \begin{bmatrix}
                | \\
                A_j\\
                |
                \end{bmatrix}
                d_{jk}
                \begin{bmatrix}
                - & b_k^T & -
                \end{bmatrix}
              }_{M \times L}
                $$
              </p>
            </div>


              <div class='imgFixed'>
              <img src="/dcmath/figs/stills/BLOCK/mmmcolsdiagrows.png" width=100%></img>
              </div>


              <div class="txt" style="padding:40px, width:100%">
              <b> Case 8: Diagonal \(D\) </b>
              <p>
                If \(D\) is diagonal (as in the case of a diagonalization),
                we have one sum of outer products
                $$
                ADB =
                \begin{bmatrix}
                | & & |\\
                A_1 & \cdots & A_N \\
                | & & |\\
                \end{bmatrix}
                \underbrace{
                \begin{bmatrix}
                d_{11} & \cdots & 0 \\
                \vdots & & \vdots \\
                0 & \cdots & d_{NN}
                \end{bmatrix}
                }_{D}
                \begin{bmatrix}
                - & b_1^T & - \\
                \vdots & & \vdots \\
                - & b_N^T & -
                \end{bmatrix}
                =
                \sum_j
                \underbrace{
                \begin{bmatrix}
                | \\
                A_j\\
                |
                \end{bmatrix}
                d_{jj}
                \begin{bmatrix}
                - & b_j^T & -
                \end{bmatrix}
              }_{M \times L}
                $$
              </p>


              </div>





        </div>
        </div>
        <!-- <script type='module' src="/dcmath/src/roto.js"> </script> -->
        <script src="/dcmath/src/extra/includeHTML.js"> </script>
      </body>
    </html>
